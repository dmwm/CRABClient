#!/usr/bin/env python
"""
This contains the hooks to call the different command plug-ins.
It is not intended to contain any of the CRAB-3 client logic,
it simply:
  - intercepts the CLI options and command
  - loads and calls the specified command
  - exit with the proper exit codes
"""
import sys
if sys.version_info < (2, 6):
    print '\nError: using a version of python < 2.6. Exiting...\n'
    sys.exit()

import pycurl
import logging
import logging.handlers

from httplib import HTTPException

from ServerUtilities import FEEDBACKMAIL

from CRABClient.CRABOptParser import CRABOptParser
from CRABClient import __version__ as client_version
from CRABClient.ClientMapping import parametersMapping
from CRABClient.ClientExceptions import ClientException
from CRABClient.ClientUtilities import getAvailCommands, uploadlogfile, initLoggers, setConsoleLogLevelVar, StopExecution, flushMemoryLogger


class MyNullHandler(logging.Handler):
    """
    TODO: Python 2.7 supplies a null handler that will replace this.
    """
    def emit(self, record):
        """
        TODO: Python 2.7 supplies a null handler that will replace this.
        """
        pass


class CRABClient(object):
    def __init__( self ):
        """
        Get the command to run, the options to pass it and a logger instance
        at appropriate level
        """

        self.subCommands = getAvailCommands()
        self.parser = CRABOptParser(self.subCommands)


    def __call__(self):

        (options, args) = self.parser.parse_args()

        ## The default logfile destination is ./crab.log. It will be changed once we
        ## know/create the CRAB project directory.
        if options.quiet:
            setConsoleLogLevelVar(logging.WARNING)
        elif options.debug:
            setConsoleLogLevelVar(logging.DEBUG)
        self.tblogger, self.logger, self.memhandler = initLoggers()

        #Instructions needed in case of early failures: sometimes the traceback logger
        #has not been set yet.

        ## Will replace Python's sys.excepthook default function with the next function.
        ## This function is used for handling uncaught exceptions (in a Python program
        ## this happens just before the program exits).
        ## In this function:
        ## - make sure everything is logged to the crab.log file;
        ## - upload the crab.log file to the CRAB cache (if there is a valid proxy).
        ## However, we already have a `finally' clause where we make sure everything is
        ## logged to the crab log file.
        def log_exception(exc_type, exc_value, tback):
            """
            Send a short version of the exception to the console,
            a long version to the log

            Adapted from Doug Hellmann

            This might help sometimes:
            import traceback,pprint;
            pprint.pprint(traceback.format_tb(tback))
            """
            clientinstance = self

            ## Add to the CRAB3 logger a file handler to the log file (if it doesn't have it
            ## already).
            tbLogger = logging.getLogger('CRAB3')
            hasFileHandler = False
            for h in tbLogger.handlers:
                if isinstance(h, logging.FileHandler) and h.stream.name == client.logger.logfile:
                    hasFileHandler = True
            if not hasFileHandler:
                filehandler = logging.FileHandler(client.logger.logfile)
                ff = logging.Formatter("%(levelname)s %(asctime)s: \t %(message)s")
                filehandler.setFormatter(ff)
                tbLogger.addHandler(filehandler)
            ## This goes to the log file.
            tbLogger.error("Unhandled Exception!")
            tbLogger.error(exc_value, exc_info = (exc_type, exc_value, tback))

            ## This goes to the console (via the CRAB3.all logger) and to the log file (via
            ## the parent CRAB3 logger).
            logger = logging.getLogger('CRAB3.all')
            logger.error("ERROR: %s: %s" % (exc_type.__name__, exc_value))
            logger.error("\n\tPlease email %s for support with the crab.log file or crab.log URL." % (FEEDBACKMAIL))
            logger.error("\tClient Version: %s" % client_version)

            ## Upload the log file.
            if hasattr(clientinstance, 'cmd') and hasattr(clientinstance.cmd, 'proxyfilename') and clientinstance.cmd.proxyfilename != None:
                try:
                    logurl = uploadlogfile(tbLogger, clientinstance.cmd.proxyfilename, logfilename = None, \
                                           logpath = str(client.logger.logfile), instance = 'prod')
                    msg  = "\tThe log file %s has been uploaded automatically to the CRAB cache." % (client.logger.logfile)
                    msg += "\n\tPlease email the following URL '%s' to %s if you need help from Analysis Operations." % (logurl, FEEDBACKMAIL)
                    logger.error(msg)
                except Exception:
                    logger.debug('Failed to upload log file automatically')
                    logger.error("\tPlease use 'crab uploadlog' to upload the log file %s to the CRAB cache." % (client.logger.logfile))
            else:
                logger.error("\tPlease use 'crab uploadlog' to upload the log file %s to the CRAB cache." % (client.logger.logfile))

        sys.excepthook = log_exception

        # check that the command is valid
        if len(args) == 0:
            print "You have not specified a command."
            # Described the valid commands in epilog, reuse here
            print self.parser.epilog
            sys.exit(-1)

        sub_cmd = None
        try:
            sub_cmd = next( v for k,v in self.subCommands.items() if args[0] in v.shortnames or args[0]==v.name)
        except StopIteration:
            print "'" + str(args[0]) + "' is not a valid command."
            print self.parser.print_help()
            sys.exit(-1)
        self.cmd = sub_cmd(self.logger, args[1:])

        self.cmd()


if __name__ == "__main__":
    # Create the crab object and start it
    # Handled in a try/except to run in a controlled environment
    #  - do not want to expose known exception to the outside
    #  - exceptions thrown in the client should exit and set an approprate
    #    exit code, this is a safety net
    exitcode = 1
    client = CRABClient()
    try:
        client()
        exitcode = 0 #no exceptions no errors
    except HTTPException as he:
        client.logger.info("The server answered with an error.")
        if he.status==503 and he.result.find("CMSWEB Error: Service unavailable")!=-1:
            client.logger.info("It seems the CMSWEB frontend is not responding. Please check: https://twiki.cern.ch/twiki/bin/viewauth/CMS/ScheduledInterventions")
        if he.headers.has_key('X-Error-Detail'):
            client.logger.info('Server answered with: %s' % he.headers['X-Error-Detail'])
        if he.headers.has_key('X-Error-Info'):
            reason = he.headers['X-Error-Info']
            for parname in parametersMapping['on-server']:
                for tmpmsg in ['\''+parname+'\' parameter', 'Parameter \''+parname+'\'']:
                    if tmpmsg in reason and parametersMapping['on-server'][parname]['config']:
                        reason = reason.replace(tmpmsg,tmpmsg.replace(parname, ' or '.join(parametersMapping['on-server'][parname]['config'])))
                        break
                else:
                    continue
                break
            client.logger.info('Reason is: %s' % reason)
        if he.headers.has_key('X-Error-Id'):
            client.logger.info('This error id might help operators investigate the issue in the server: %s' % he.headers['X-Error-Id'])
        #The following goes to the logfile.
        errmsg = "ERROR: %s (%s): " % (he.reason, he.status)
        ## answer can be a json or not
        try:
            errmsg += " '%s'" % he.result
        except ValueError:
            pass
        client.logger.debug(errmsg)
        client.logger.debug('Command failed with URI: %s' % he.url)
        client.logger.debug('     Input data: %s' % he.req_data)
        client.logger.debug('     Request headers: %s' % he.headers)
        logging.getLogger('CRAB3').exception('Caught exception')
        exitcode = he.status
    except pycurl.error as  pe:
        client.logger.error(pe)
        logging.getLogger('CRAB3').exception('Caught exception')
        exitcode = pe.args[0]
        if pe[1].find('(DNS server returned answer with no data)'):
            client.logger.info("It seems the CMSWEB frontend is not responding. Please check: https://twiki.cern.ch/twiki/bin/viewauth/CMS/ScheduledInterventions")
    except ClientException as ce:
        client.logger.error(ce)
        logging.getLogger('CRAB3').exception('Caught exception')
        exitcode = ce.exitcode
    except KeyboardInterrupt:
        client.logger.error('Keyboard Interrupted')
    except StopExecution:
        exitcode = 0
    finally:
        # the command crab --version does not have a logger instance
        if hasattr(client, 'tblogger') and hasattr(client, 'memhandler') and hasattr(client, 'logger'):
            flushMemoryLogger(client.tblogger, client.memhandler, client.logger.logfile)

    if hasattr(client, 'cmd'):
        client.cmd.terminate( exitcode )

    sys.exit( exitcode )
